#!/usr/bin/env python

"""The goal of this notebook is to generate LegacySurvey (*grzW1W2*) coadds of all
the central galaxies (and their surrounding groups and clusters) in the
legacyhalos parent sample (*legacyhalos-upenn-parent.fits*).

Please note:

* This notebook must be run from the jupyter-dev.nersc.gov notebook server in
  order to access the LegacySurvey data.

* We assume that the \$LEGACYHALOS_DIR directory exists (in $CSCRATCH) with all
  the latest parent catalogs.

* We do not yet build unWISE coadds.

* We assume the DECam pixel scale (since we use just DR5 data).

* The code will not handle clusters that span one or more bricks -- a ToDo would
  be to define custom bricks and generate custom Tractor catalogs.
"""

#- Parse args first to enable --help on login nodes where MPI crashes
from __future__ import absolute_import, division, print_function
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('-c', '--config', default='input.yaml')
parser.add_argument('-O', '--output_dir', help='Path to write the outputs', type=str, default='./')
parser.add_argument('-s', '--seed', help='Seed for random number generation', type=int, default=None)
parser.add_argument('-n', '--nproc', type=int, help='number of concurrent processes to use [{}]'.format(nproc), default=nproc)
parser.add_argument('--nside', help='Divide the DESI footprint into this healpix resolution', type=int, default=64)
parser.add_argument('--tiles', help='Path to file with tiles to cover', type=str)
parser.add_argument('--npix', help='Number of healpix per process', type=int, default=1)
parser.add_argument('--healpixels', help='Integer list of healpix pixels (corresponding to nside) to process.', type=int, nargs='*', default=None)
parser.add_argument('-v','--verbose', action='store_true', help='Enable verbose output.')
parser.add_argument('--no-check-env', action='store_true', help="Don't check NERSC environment variables")
parser.add_argument('--sort-pixels', action='store_true', help="Sort pixels by galactic latitude")

args = parser.parse_args()

#- Then initialize MPI ASAP before proceeding with other imports
from mpi4py import MPI
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

import os, sys, shutil
import numpy as np
import matplotlib.pyplot as plt

from astropy.io import fits
from astropy.cosmology import WMAP9 as cosmo

from legacypipe.survey import LegacySurveyData
from astrometry.util.fits import fits_table

#- NERSC environment check
if 'NERSC_HOST' in os.environ and not args.no_check_env:
    ok = True
    if os.getenv('OMP_NUM_THREADS') not in ('1', '2'):
        ok = False
        if rank == 0:
            log.error('You likely want $OMP_NUM_THREADS=1 at NERSC')
    if os.getenv('MPICH_GNI_FORK_MODE') != 'FULLCOPY':
        ok = False
        if rank == 0:
            log.error('You likely want $MPICH_GNI_FORK_MODE=FULLCOPY at NERSC')
    if os.getenv('KMP_AFFINITY') != 'disabled':
        ok = False
        if rank == 0:
            log.error('You likely want $KMP_AFFINITY=disabled at NERSC')
    if not ok:
        if rank == 0:
            log.error('Either fix env or rerun with --no-check-env; exiting...')
        sys.exit(1)

# Calculate which pixels cover these tiles and broadcast to all ranks
if rank == 0:
    if args.tiles is not None:
        if args.tiles.endswith('.ecsv'):
            tiles = Table.read(args.tiles, format='ascii.ecsv')
        else:
            tiles = Table.read(args.tiles)

        log.info('{} tiles'.format(len(tiles)))
        pixels = desimodel.footprint.tiles2pix(args.nside, tiles)
    else:
        pixels = np.array(args.healpixels)

    keep = list()
    for i, pixnum in enumerate(pixels):
        truthspecfile = mockio.findfile('truth', args.nside, pixnum,
                                        basedir=args.output_dir)
        if not os.path.exists(truthspecfile):
            keep.append(i)

    log.info('{}/{} pixels remaining to do'.format(len(keep), len(pixels)))
    pixels = pixels[keep]

    #- pre-create output directories
    for pixnum in pixels:
        outdir = os.path.dirname(mockio.findfile('blat', args.nside, pixnum,
                                                 basedir=args.output_dir))
        if not os.path.isdir(outdir):
            os.makedirs(outdir, exist_ok=True)  #- belt and suspenders



comm.barrier()
pixels = comm.bcast(pixels, root=0)

#- Read config file and broadcast to all ranks
if rank == 0:
    import yaml
    with open(args.config, 'r') as pfile:
        params = yaml.load(pfile)
else:
    params = None

params = comm.bcast(params, root=0)

#- Generate a different random seed for each pixel
np.random.seed(args.seed)
randseeds = np.random.randint(2**31, size=len(pixels))

#- Split the pixels into groups for each rank
iedges = np.linspace(0, len(pixels), size+1, dtype=int)
rankpix = pixels[iedges[rank]:iedges[rank+1]]
rankseeds = randseeds[iedges[rank]:iedges[rank+1]]
log.info('rank {} processes {} pixels {}'.format(rank, iedges[rank+1]-iedges[rank], rankpix))
sys.stdout.flush()
comm.barrier()

if len(rankpix) > 0:
    #- Process one pixel at a time to avoid blowing out memory, but structure
    #- it in a way that we could expand to multiple pixels per call if/when
    #- we use less memory.
    n = args.npix
    for i in range(0, len(rankpix), n):
        logfile = mockio.findfile('build', args.nside, rankpix[i], ext='log', basedir=args.output_dir)
        log.info('Logging pixels {} to {}'.format(rankpix[i:i+n], logfile))
        t0 = time.time()
        try:
            with stdouterr_redirected(to=logfile):
                targets_truth(params, args.output_dir, seed=rankseeds[i], nside=args.nside,
                            nproc=args.nproc, verbose=args.verbose,
                            healpixels=rankpix[i:i+n])

            runtime = (time.time()-t0) / 60
            log.info('Pixels {} took {:.1f} minutes'.format(rankpix[i:i+n], runtime))
        except Exception as err:
            runtime = (time.time()-t0) / 60
            log.error('Pixels {} failed after {:.1f} minutes'.format(rankpix[i:i+n], runtime))
            import traceback
            msg = traceback.format_exc()
            sys.stdout.flush()
            sys.stderr.flush()




from astrometry.util.multiproc import multiproc
mp = multiproc()


legacyhalos_dir = os.path.join( os.getenv('SCRATCH'), 'legacyhalos' )
dr5_dir = os.path.join(os.sep, 'project', 'projectdirs', 'cosmo', 'data', 'legacysurvey', 'dr5')
parentfile = os.path.join(legacyhalos_dir, 'legacyhalos-upenn-parent.fits')

coaddsdir = os.path.join(legacyhalos_dir, 'coadds')
if not os.path.exists(coaddsdir):
    os.makedirs(coaddsdir)


bands = ['g', 'r', 'z']

survey = LegacySurveyData(cache_dir=dr5_dir)

bcgphot = fits_table(parentfile, ext='LSPHOT')
redcat = fits_table(parentfile, ext='REDMAPPER')
print('Read {} galaxies from {}'.format(len(bcgphot), parentfile))

# ### Get the desired radius of the cutout for each central.

# To get a sensible radius we use the quantity R_LAMBDA from the redmapper
# cluster catalog, which quantifies the "richness radius" in h^-1 Mpc and
# convert it to pixels using a standard cosmology, times a fudge factor
# (currently 1.5).
# 
# Note that we assume the DECam pixel scale of 0.262 arcsec/pix!
# 
# Finally, we bound the radius to the interval [50, 500] pixels.

def coadds_radius(redcat, pixscale=0.262, factor=1.5, rmin=50, rmax=500):

"""Get the desired radius of each cluster in pixels 
    using the R_LAMBDA, which is the richness radius in 
    h^-1 Mpc.
    
    """
    print('NB: Assuming DECam data with pixel scale = {:.3f} arcsec/pix'.format(pixscale))
    radius = redcat.r_lambda * 1e3 * cosmo.h # cluster radius in kpc
    rad_arcsec = [factor * pixscale * rad * cosmo.arcsec_per_kpc_proper(cat.z).value for 
                  rad, cat in zip(radius, redcat)]
    rad = np.array(rad_arcsec).astype('int16')
    
    rad[rad < rmin] = rmin
    rad[rad > rmax] = rmax

    return rad

radius = coadds_radius(redcat)



def coadds_stage_tims(bcg, radius=100):
    """Initialize the first step of the pipeline, returning
    a dictionary with the following keys:
    
    ['brickid', 'target_extent', 'version_header', 
     'targetrd', 'brickname', 'pixscale', 'bands', 
     'survey', 'brick', 'ps', 'H', 'ccds', 'W', 
     'targetwcs', 'tims']

    """
    from legacypipe.runbrick import stage_tims
    
    bbox = [bcg.bx-radius, bcg.bx+radius, bcg.by-radius, bcg.by+radius]
    P = stage_tims(brickname=bcg.brickname, survey=survey, target_extent=bbox,
                   pixPsf=True, hybridPsf=True, depth_cut=False, mp=mp)
    return P

def read_tractor(bcg, targetwcs, verbose=True):
    """Read the full Tractor catalog for a given brick 
    and remove the BCG.
    
    """
    H, W = targetwcs.shape

    # Read the full Tractor catalog.
    fn = survey.find_file('tractor', brick=bcg.brickname)
    cat = fits_table(fn)
    if verbose:
        print('Read {} sources from {}'.format(len(cat), fn))
    
    # Restrict to just the sources in our little box. 
    ok, xx, yy = targetwcs.radec2pixelxy(cat.ra, cat.dec)
    cat.cut(np.flatnonzero((xx > 0) * (xx < W) * (yy > 0) * (yy < H)))
    if verbose:
        print('Cut to {} sources within our box.'.format(len(cat)))
    
    # Remove the central galaxy.
    cat.cut(np.flatnonzero(cat.objid != bcg.objid))
    if verbose:
        print('Removed central galaxy with objid = {}'.format(bcg.objid))
        
    return cat


def build_model_image(cat, tims, verbose=True):
    """Generate a model image by rendering each source.
    
    """
    from legacypipe.catalog import read_fits_catalog
    from legacypipe.runbrick import _get_mod
    
    if verbose:
        print('Creating tractor sources...')
    srcs = read_fits_catalog(cat, fluxPrefix='')
    
    if False:
        print('Sources:')
        [print(' ', src) for src in srcs]

    if verbose:
        print('Rendering model images...')
    mods = [_get_mod((tim, srcs)) for tim in tims]

    return mods

def build_coadds(bcg, targetwcs, tims, mods, version_header, verbose=True):
    """Generate individual-band FITS and color coadds for each central.
    
    """
    from legacypipe.coadds import make_coadds, write_coadd_images
    from legacypipe.runbrick import rgbkwargs, rgbkwargs_resid
    from legacypipe.survey import get_rgb, imsave_jpeg
    
    if verbose:
        print('Producing coadds...')
    C = make_coadds(tims, bands, targetwcs, mods=mods, mp=mp,
                    callback=write_coadd_images,
                    callback_args=(survey, bcg.brickname, version_header, 
                                   tims, targetwcs)
                    )
    
    # Move (rename) the coadds into the desired output directory.
    for suffix in ('chi2', 'image', 'invvar', 'model'):
        for band in bands:
            oldfile = os.path.join(survey.output_dir, 'coadd', bcg.brickname[:3], 
                                   bcg.brickname, 'legacysurvey-{}-{}-{}.fits.fz'.format(
                    bcg.brickname, suffix, band))
            newfile = os.path.join(survey.output_dir, '{:05d}-{}-{}.fits.fz'.format(bcg.objid, suffix, band))
            shutil.move(oldfile, newfile)
    shutil.rmtree(os.path.join(survey.output_dir, 'coadd'))
    
    # Build png postage stamps of the coadds.
    coadd_list = [('image', C.coimgs,   rgbkwargs),
                  ('model', C.comods,   rgbkwargs),
                  ('resid', C.coresids, rgbkwargs_resid)]

    for name, ims, rgbkw in coadd_list:
        rgb = get_rgb(ims, bands, **rgbkw)
        kwa = {}
        outfn = os.path.join(survey.output_dir, '{:05d}-{}.jpg'.format(bcg.objid, name))
        if verbose:
            print('Writing {}'.format(outfn))
        imsave_jpeg(outfn, rgb, origin='lower', **kwa)
        del rgb


#for ii in range(bcgphot):
for ii in range(2):
    survey.output_dir = os.path.join(coaddsdir, '{:05d}'.format(bcgphot[ii].objid))

    # Step 1 - Set up the first stage of the pipeline.
    P = coadds_stage_tims(bcgphot[ii], radius=radius[ii])
    
    # Step 2 - Read the Tractor catalog for this brick and remove the central.
    cat = read_tractor(bcgphot[ii], P['targetwcs'])
           
    # Step 3 - Render the model images without the central.
    mods = build_model_image(cat, tims=P['tims'])

    # Step 4 - Generate and write out the coadds.
    build_coadds(bcgphot[ii], P['targetwcs'], P['tims'], mods, P['version_header'])

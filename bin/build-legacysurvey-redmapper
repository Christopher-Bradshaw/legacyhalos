#!/usr/bin/env python
"""
Match the redMaPPer sample to the Legacy Surveys DR8 footprint.

time build-legacysurvey-redmapper --nproc 24 --chunk 0
time build-legacysurvey-redmapper --nproc 24 --chunk 1
time build-legacysurvey-redmapper --nproc 24 --chunk 2
time build-legacysurvey-redmapper --nproc 24 --chunk 3
time build-legacysurvey-redmapper --merge-chunks

"""
import os, sys, pdb
import numpy as np
from time import time
from glob import iglob, glob
import fitsio

from astropy.wcs import WCS
import legacyhalos.io
from legacyhalos.desiutil import brickname as get_brickname_from_radec

import multiprocessing
nproc_default = multiprocessing.cpu_count() // 2

start = time()

releasedict = {3000: 'S', 4000: 'N', 5000: 'S', 6000: 'N', 7000: 'S', 7999: 'S',
               8000: 'S', 8001: 'N'}

def resolve_dec():
    """Default Dec cut to separate targets in BASS/MzLS from DECaLS."""
    dec = 32.375
    return dec

def release_to_photsys(release):
    """Convert RELEASE to PHOTSYS using the releasedict lookup table.

    Parameters
    ----------
    objects : :class:`int` or :class:`~numpy.ndarray`
        RELEASE column from a numpy rec array of targets.

    Returns
    -------
    :class:`str` or :class:`~numpy.ndarray`
        'N' if the RELEASE corresponds to the northern photometric
        system (MzLS+BASS) and 'S' if it's the southern system (DECaLS).

    Notes
    -----
    Flags an error if the system is not recognized.
    """
    # ADM arrays of the key (RELEASE) and value (PHOTSYS) entries in the releasedict.
    releasenums = np.array(list(releasedict.keys()))
    photstrings = np.array(list(releasedict.values()))

    # ADM explicitly check no unknown release numbers were passed.
    unknown = set(release) - set(releasenums)
    if bool(unknown):
        msg = 'Unknown release number {}'.format(unknown)
        print(msg)
        raise ValueError(msg)

    # ADM an array with indices running from 0 to the maximum release number + 1.
    r2p = np.empty(np.max(releasenums)+1, dtype='|S1')

    # ADM populate where the release numbers exist with the PHOTSYS.
    r2p[releasenums] = photstrings

    # ADM return the PHOTSYS string that corresponds to each passed release number.
    return r2p[release]

def _isonnorthphotsys(photsys):
    """ If the object is from the northen photometric system """
    # ADM explicitly checking for NoneType. I can't see why we'd ever want to
    # ADM run this test on empty information. In the past we have had bugs where
    # ADM we forgot to populate variables before passing them
    if photsys is None:
        raise ValueError("NoneType submitted to _isonnorthphotsys function")

    psftype = np.asarray(photsys)
    # ADM in Python3 these string literals become byte-like
    # ADM so to retain Python2 compatibility we need to check
    # ADM against both bytes and unicode
    northern = ((photsys == 'N') | (photsys == b'N'))
    return northern

def is_in_gal_box(objs, lbbox, radec=False):
    """Determine which of an array of objects are in a Galactic l, b box.

    Parameters
    ----------
    objs : :class:`~numpy.ndarray` or `list`
        An array of objects. Must include at least the columns "RA" and "DEC".
    radecbox : :class:`list`
        4-entry list of coordinates [lmin, lmax, bmin, bmax] forming the
        edges of a box in Galactic l, b (degrees).
    radec : :class:`bool`, optional, defaults to ``False``
        If ``True`` then the passed `objs` is an [RA, Dec] list instead of
        a rec array.

    Returns
    -------
    :class:`~numpy.ndarray`
        ``True`` for objects in the box, ``False`` for objects outside of the box.

    Notes
    -----
        - Tests the minimum l/b with >= and the maximum with <

    """
    from astropy.coordinates import SkyCoord
    from astropy import units as u
    
    lmin, lmax, bmin, bmax = lbbox

    # ADM check for some common mistakes.
    if bmin < -90. or bmax > 90. or bmax <= bmin or lmax <= lmin:
        msg = "Strange input: [lmin, lmax, bmin, bmax] = {}".format(lbbox)
        print(msg)
        raise ValueError(msg)

    # ADM convert input RA/Dec to Galactic coordinates.
    if radec:
        ra, dec = objs
    else:
        ra, dec = objs["RA"], objs["DEC"]

    c = SkyCoord(ra*u.degree, dec*u.degree)
    gal = c.galactic

    # ADM and limit to (l, b) ranges.
    ii = ((gal.l.value >= lmin) & (gal.l.value < lmax)
          & (gal.b.value >= bmin) & (gal.b.value < bmax))

    return ii

def doresolve(targets):
    """Resolve which targets are primary in imaging overlap regions.

    Parameters
    ----------
    targets : :class:`~numpy.ndarray`
        Rec array of targets. Must have columns "RA" and "DEC" and
        either "RELEASE" or "PHOTSYS".

    Returns
    -------
    :class:`~numpy.ndarray`
        The original target list trimmed to only objects from the "northern"
        photometry in the northern imaging area and objects from "southern"
        photometry in the southern imaging area.
    
    """
    import healpy as hp
    from legacyhalos.misc import pixarea2nside
    
    # ADM retrieve the photometric system from the RELEASE.
    if 'PHOTSYS' in targets.dtype.names:
        photsys = targets["PHOTSYS"]
    else:
        photsys = release_to_photsys(targets["RELEASE"])

    # ADM a flag of which targets are from the 'N' photometry.
    photn = _isonnorthphotsys(photsys)

    # ADM grab the declination used to resolve targets.
    split = resolve_dec()

    # ADM determine which targets are north of the Galactic plane. As
    # ADM a speed-up, bin in ~1 sq.deg. HEALPixels and determine
    # ADM which of those pixels are north of the Galactic plane.
    # ADM We should never be as close as ~1o to the plane.
    nside = pixarea2nside(1)
    theta, phi = np.radians(90-targets["DEC"]), np.radians(targets["RA"])
    pixnum = hp.ang2pix(nside, theta, phi, nest=True)
    # ADM find the pixels north of the Galactic plane...
    allpix = np.arange(hp.nside2npix(nside))
    theta, phi = hp.pix2ang(nside, allpix, nest=True)
    ra, dec = np.degrees(phi), 90-np.degrees(theta)
    pixn = is_in_gal_box([ra, dec], [0., 360., 0., 90.], radec=True)
    # ADM which targets are in pixels north of the Galactic plane.
    galn = pixn[pixnum]

    # ADM which targets are in the northern imaging area.
    arean = (targets["DEC"] >= split) & galn

    # ADM retain 'N' targets in 'N' area and 'S' in 'S' area.
    keep = (photn & arean) | (~photn & ~arean)

    return targets[keep]

def dr_extension(drdir):
    """Determine the extension information for files in a legacy survey coadd directory

    Parameters
    ----------
    drdir : :class:`str`
       The root directory pointing to a Data Release from the Legacy Surveys
       e.g. /global/project/projectdirs/cosmo/data/legacysurvey/dr7.

    Returns
    -------
    :class:`str`
        Whether the file extension is 'gz' or 'fz'.
    :class:`int`
        The corresponding FITS extension number that needs to be read (0 or 1).
    """

    from glob import iglob

    # ADM for speed, create a generator of all of the nexp files in the coadd directory.
    gen = iglob(drdir+"/coadd/*/*/*nexp*")
    # ADM and pop the first one.
    anexpfile = next(gen)
    extn = anexpfile[-2:]

    if extn == 'gz':
        return 'gz', 0

    return 'fz', 1

def quantities_at_positions_in_a_brick(ras, decs, brickname, drdir, aprad=0.75):
    """Observational quantities (per-band) at positions in a Legacy Surveys brick.

    Parameters
    ----------
    ras : :class:`~numpy.array`
        Right Ascensions of interest (degrees).
    decs : :class:`~numpy.array`
        Declinations of interest (degrees).
    brickname : :class:`str`
        Name of brick which contains RA/Dec positions, e.g., '1351p320'.
    drdir : :class:`str`
       The root directory pointing to a Data Release from the Legacy Surveys
       e.g. /global/project/projectdirs/cosmo/data/legacysurvey/dr7.
    aprad : :class:`float`, optional, defaults to 0.75
        Radii in arcsec of aperture for which to derive sky fluxes
        defaults to the DESI fiber radius.
    Returns
    -------
    :class:`dictionary`
       The number of observations (`nobs_x`), PSF depth (`psfdepth_x`)
       Galaxy depth (`galdepth_x`), PSF size (`psfsize_x`), sky
       background (`apflux_x`) and inverse variance (`apflux_ivar_x`)
       at each passed position in each band x=g,r,z. Plus, the
       `psfdepth_w1` and `_w2` depths and the `maskbits`, `wisemask_w1`
       and `_w2` information at each passed position for the brick.

    Notes
    -----
        - First version copied shamelessly from Anand Raichoor.

    """
    #t0 = time()
    #import photutils
    #import astropy.io.fits as fits
    #from astrometry.util.util import Tan

    # ADM guard against too low a density of random locations.
    npts = len(ras)
    if npts == 0:
        msg = 'brick {} is empty. Increase the density of random points!'.format(brickname)
        print(msg)
        raise ValueError(msg)

    # ADM determine whether the coadd files have extension .gz or .fz based on the DR directory.
    extn, extn_nb = dr_extension(drdir)

    # ADM the output dictionary.
    qdict = {}

    # as a speed up, we assume all images in different filters for the brick have the same WCS
    # -> if we have read it once (iswcs=True), we use this info
    iswcs = False
    # ADM this will store the instrument name the first time we touch the wcs
    instrum = None

    rootdir = os.path.join(drdir, 'coadd', brickname[:3], brickname)
    fileform = os.path.join(rootdir, 'legacysurvey-{}-{}-{}.fits.{}')
    # ADM loop through the filters and store the number of observations
    # ADM etc. at the RA and Dec positions of the passed points.
    for filt in ['g', 'r', 'z']:
        # ADM the input file labels, and output column names and output
        # ADM formats for each of the quantities of interest.
        qnames = zip(['nexp', 'depth', 'psfsize'],
                     ['nobs', 'psfdepth', 'psfsize'],
                     ['i2', 'f4', 'f4'])
        #qnames = zip(['nexp', 'depth', 'galdepth', 'psfsize', 'image'],
        #             ['nobs', 'psfdepth', 'galdepth', 'psfsize', 'apflux'],
        #             ['i2', 'f4', 'f4', 'f4', 'f4'])
        for qin, qout, qform in qnames:
            fn = fileform.format(brickname, qin, filt, extn)
            # ADM only process the WCS if there's a file for this filter.
            if os.path.exists(fn):
                img = fitsio.read(fn, ext=extn_nb)
                #img = fits.open(fn)[extn_nb]
                if not iswcs:
                    header = fitsio.read_header(fn, ext=extn_nb)
                    # ADM store the instrument name, if it isn't stored.
                    instrum = header["INSTRUME"].lower().strip()
                    #instrum = img.header["INSTRUME"].lower().strip()
                    #wcs = Tan(header['CRVAL1'], header['CRVAL2'], header['CRPIX1'], header['CRPIX2'],
                    #          header['CD1_1'], header['CD1_2'], header['CD2_1'], header['CD2_2'],
                    #          header['NAXIS1'], header['NAXIS2'])
                    w = WCS(header)
                    #w = WCS(img.header)
                    x, y = w.all_world2pix(ras, decs, 0)
                    #_, x, y = wcs.radec2pixelxy(ras, decs)
                    #x -= 1
                    #y -= 1
                    iswcs = True
                # ADM get the quantity of interest at each location and
                # ADM store in a dictionary with the filter and quantity.
                qdict[qout+'_'+filt] = img[y.astype("int"), x.astype("int")]
                #qdict[qout+'_'+filt] = img.data[y.astype("int"), x.astype("int")]
            # ADM if the file doesn't exist, set quantities to zero.
            else:
                qdict[qout+'_'+filt] = np.zeros(npts, dtype=qform)
        #print('Band {} {:.3f}'.format(filt, time()-t0))
    #print('All bands {:.3f}'.format(time()-t0))

    # ADM add the MASKBITS and WISEMASK information.
    fn = os.path.join(rootdir, 'legacysurvey-{}-maskbits.fits.{}'.format(brickname, extn))
    # ADM only process the WCS if there's a file for this filter.
    mnames = zip([extn_nb], ['maskbits'], ['>i2'])
    #mnames = zip([extn_nb, extn_nb+1, extn_nb+2],
    #             ['maskbits', 'wisemask_w1', 'wisemask_w2'],
    #             ['>i2', '|u1', '|u1'])
    for mextn, mout, mform in mnames:
        if os.path.exists(fn):
            img = fitsio.read(fn, ext=mextn)
            #img = fits.open(fn)[mextn]
            #img = fits.open(fn)[mextn]
            # ADM use the WCS for the per-filter quantities if it exists.
            if not iswcs:
                header = fitsio.read_header(fn, ext=mextn)
                # ADM store the instrument name, if it isn't yet stored.
                instrum = header["INSTRUME"].lower().strip()
                w = WCS(header)
                #instrum = img.header["INSTRUME"].lower().strip()
                #w = WCS(img.header)
                x, y = w.all_world2pix(ras, decs, 0)
                iswcs = True
            # ADM add the maskbits to the dictionary.
            qdict[mout] = img[y.astype("int"), x.astype("int")]
            #qdict[mout] = img.data[y.astype("int"), x.astype("int")]
        else:
            # ADM if no files are found, populate with zeros.
            qdict[mout] = np.zeros(npts, dtype=mform)
            # ADM if there was no maskbits file, populate with BAILOUT.
            if mout == 'maskbits':
                qdict[mout] |= 2**10

    # ADM populate the photometric system in the quantity dictionary.
    if instrum is None:
        # ADM don't count bricks where we never read a file header.
        return
    elif instrum == 'decam':
        qdict['photsys'] = np.array([b"S" for x in range(npts)], dtype='|S1')
    else:
        qdict['photsys'] = np.array([b"N" for x in range(npts)], dtype='|S1')
#    log.info('Recorded quantities for each point in brick {}...t = {:.1f}s'
#                  .format(brickname,time()-start))

    #print('Time for one brick {:.3f}'.format(time()-t0))
    #pdb.set_trace()
    
    ## ADM calculate and add WISE depths. The WCS is different for WISE.
    #iswcs = False
    ## ADM a dictionary of scalings from invvar to depth:
    #norm = {'W1': 0.240, 'W2': 0.255}
    ## ADM a dictionary of Vega-to-AB conversions:
    #vega_to_ab = {'W1': 2.699, 'W2': 3.339}
    #for band in ['W1', 'W2']:
    #    # ADM the input file labels, and output column names and output
    #    # ADM formats for each of the quantities of interest.
    #    qnames = zip(['invvar'], ['psfdepth'], ['f4'])
    #    for qin, qout, qform in qnames:
    #        fn = fileform.format(brickname, qin, band, extn)
    #        # ADM only process the WCS if there's a file for this band.
    #        if os.path.exists(fn):
    #            img = fits.open(fn)[extn_nb]
    #            # ADM calculate the WCS if it wasn't, already.
    #            if not iswcs:
    #                w = WCS(img.header)
    #                x, y = w.all_world2pix(ras, decs, 0)
    #                iswcs = True
    #            # ADM get the inverse variance at each location.
    #            ivar = img.data[y.astype("int"), x.astype("int")]
    #            # ADM convert to WISE depth in AB. From Dustin Lang on the
    #            # decam-chatter mailing list on 06/20/19, 1:59PM MST:
    #            # psfdepth_Wx_AB = invvar_Wx * norm_Wx**2 / fluxfactor_Wx**2
    #            # where fluxfactor = 10.** (dm / -2.5), dm = vega_to_ab[band]
    #            ff = 10.**(vega_to_ab[band] / -2.5)
    #            # ADM store in a dictionary with the band and quantity.
    #            qdict[qout+'_'+band] = ivar * norm[band]**2 / ff**2
    #        # ADM if the file doesn't exist, set quantities to zero.
    #        else:
    #            qdict[qout+'_'+band] = np.zeros(npts, dtype=qform)

    return qdict

def dr8_quantities_at_positions_in_a_brick(ras, decs, brickname, drdir):
    """Wrap `quantities_at_positions_in_a_brick` for DR8 and beyond.

    Notes
    -----
    - See :func:`~desitarget.randoms.quantities_at_positions_in_a_brick`
      for details. This wrapper looks for TWO coadd directories in
      `drdir` (one for DECaLS, one for MzLS/BASS) and, if it finds two,
      creates randoms for both surveys within the the passed brick. The
      wrapper also defaults to the behavior for only having one survey.
    """
    # ADM determine if we must traverse two sets of brick directories.
    wcoadd = glob(os.path.join(drdir, '*', "coadd"))
    drdirs = [os.path.dirname(dd) for dd in wcoadd]

    # ADM make the dictionary of quantities for one or two directories.
    t0 = time()
    qall = []
    for dd in drdirs:
        q = quantities_at_positions_in_a_brick(ras, decs, brickname, dd)
        # ADM don't count bricks where we never read a file header.
        if q is not None:
            qall.append(q)
    #print('Time for quantities_at_positions_in_a_brick = {:.3f} s'.format(time()-t0))

    # ADM concatenate everything in qall into one dictionary.
    qcombine = {}
    # ADM catch the case where a coadd directory is completely missing.
    if len(qall) == 0:
        print("missing brick: {}".format(brickname))
    else:
        for k in qall[0].keys():
            qcombine[k] = np.concatenate([q[k] for q in qall])

    return qcombine

def get_quantities_in_a_brick(ras, decs, brickname, drdir=None,
                              dustdir=None, zeros=False):
    """NOBS, DEPTHS etc. (per-band) for random points in a brick of the Legacy Surveys

    Parameters
    ----------
    ramin : :class:`float`
        The minimum "edge" of the brick in Right Ascension
    ramax : :class:`float`
        The maximum "edge" of the brick in Right Ascension
    decmin : :class:`float`
        The minimum "edge" of the brick in Declination
    decmax : :class:`float`
        The maximum "edge" of the brick in Declination
    brickname : :class:`~numpy.array`
        Brick names that corresponnds to the brick edges, e.g., '1351p320'
    density : :class:`int`, optional, defaults to 100,000
        The number of random points to return per sq. deg. As a typical brick is
        ~0.25 x 0.25 sq. deg. about (0.0625*density) points will be returned
    dustdir : :class:`str`, optional, defaults to $DUST_DIR+'/maps'
        The root directory pointing to SFD dust maps. If not
        sent the code will try to use $DUST_DIR+'/maps' before failing.
    aprad : :class:`float`, optional, defaults to 0.75
        Radii in arcsec of aperture for which to derive sky fluxes
        defaults to the DESI fiber radius.
    zeros : :class:`bool`, optional, defaults to ``False``
        If ``True`` then don't look up pixel-level information for the
        brick, just return zeros. The only quantities populated are
        those that don't need pixels (`RA`, `DEC`, `BRICKNAME`, `EBV`)
        and the `NOBS_` quantities (which are set to zero).
    drdir : :class:`str`, optional, defaults to None
        The root directory pointing to a DR from the Legacy Surveys
        e.g. /global/project/projectdirs/cosmo/data/legacysurvey/dr7.
        Only necessary to pass if zeros is ``False``.

    Returns
    -------
    :class:`~numpy.ndarray`
        a numpy structured array with the following columns:
            RA, DEC: Right Ascension, Declination of a random location.
            BRICKNAME: Passed brick name.
            NOBS_G, R, Z: Number of observations in g, r, z-band.
            PSFDEPTH_G, R, Z: PSF depth at this location in g, r, z.
            GALDEPTH_G, R, Z: Galaxy depth in g, r, z.
            PSFDEPTH_W1, W2: (PSF) depth in W1, W2 (AB mag system).
            PSFSIZE_G, R, Z: Weighted average PSF FWHM (arcsec).
            APFLUX_G, R, Z: Sky background extracted in `aprad`.
            APFLUX_IVAR_G, R, Z: Inverse variance of sky background.
            MASKBITS: mask information. See header of extension 1 of e.g.
              'coadd/132/1320p317/legacysurvey-1320p317-maskbits.fits.fz'
            WISEMASK_W1: mask info. See header of extension 2 of e.g.
              'coadd/132/1320p317/legacysurvey-1320p317-maskbits.fits.fz'
            WISEMASK_W2: mask info. See header of extension 3 of e.g.
              'coadd/132/1320p317/legacysurvey-1320p317-maskbits.fits.fz'
            EBV: E(B-V) at this location from the SFD dust maps.

    """
    from legacyhalos.dust import SFDMap

    # ADM this is only intended to work on one brick, so die if a larger array is passed.
    qdict = {}
    if not isinstance(brickname, str):
        print("Only one brick can be passed at a time!")
        raise ValueError

    if not zeros:
        # ADM only look up pixel-level quantities if zeros was not sent.
        # ADM retrieve the dictionary of quantities at each location.
        qdict = dr8_quantities_at_positions_in_a_brick(ras, decs, brickname,
                                                       drdir)

        # ADM catch the case where a coadd directory is completely missing.
        if len(qdict) > 0:
            # ADM if 2 different camera combinations overlapped a brick
            # ADM then we need to duplicate the ras, decs as well.
            if len(qdict['photsys']) == 2*len(ras):
                ras = np.concatenate([ras, ras])
                decs = np.concatenate([decs, decs])

        # ADM the structured array to output.
        qinfo = np.zeros(
            len(ras),
            dtype=[('RA', 'f8'), ('DEC', 'f8'), ('BRICKNAME', 'S8'),
                   ('NOBS_G', 'i2'), ('NOBS_R', 'i2'), ('NOBS_Z', 'i2'),
                   ('PSFDEPTH_G', 'f4'), ('PSFDEPTH_R', 'f4'), ('PSFDEPTH_Z', 'f4'),
                   #('GALDEPTH_G', 'f4'), ('GALDEPTH_R', 'f4'), ('GALDEPTH_Z', 'f4'),
                   #('PSFDEPTH_W1', 'f4'), ('PSFDEPTH_W2', 'f4'),
                   ('PSFSIZE_G', 'f4'), ('PSFSIZE_R', 'f4'), ('PSFSIZE_Z', 'f4'),
                   #('APFLUX_G', 'f4'), ('APFLUX_R', 'f4'), ('APFLUX_Z', 'f4'),
                   #('APFLUX_IVAR_G', 'f4'), ('APFLUX_IVAR_R', 'f4'), ('APFLUX_IVAR_Z', 'f4'),
                   ('MASKBITS', 'i2'),
                   #('WISEMASK_W1', '|u1'), ('WISEMASK_W2', '|u1'),
                   #('EBV', 'f4'),
                   ('PHOTSYS', '|S1')]
        )
    else:
        qinfo = np.zeros(
            len(ras),
            dtype=[('RA', 'f8'), ('DEC', 'f8'), ('BRICKNAME', 'S8'),
                   ('NOBS_G', 'i2'), ('NOBS_R', 'i2'), ('NOBS_Z', 'i2'),
                   ('EBV', 'f4')]
        )

    # ADM retrieve the E(B-V) values for each random point.
    #ebv = SFDMap(mapdir=dustdir).ebv(ras, decs, scaling=0.86)

    # ADM we only looked up pixel-level quantities if zeros wasn't sent.
    if not zeros:
        # ADM catch the case where a coadd directory was missing.
        if len(qdict) > 0:
            # ADM store each quantity of interest in the structured array
            # ADM remembering that the dictionary keys are lower-case text.
            cols = qdict.keys()
            for col in cols:
                qinfo[col.upper()] = qdict[col]

    # ADM add the RAs/Decs and brick name.
    qinfo["RA"], qinfo["DEC"], qinfo["BRICKNAME"] = ras, decs, brickname

    # ADM add the dust values.
    #qinfo["EBV"] = ebv

    return qinfo

def _get_brickname_from_radec(args):
    return get_brickname_from_radec(*args)

def imaging_properties_bricks(ra, dec, brickdict, bricknames, cat_bricknames,
                              nproc=32, zeros=False, dustdir=None):

    """Parallel-process a random catalog for a set of brick names.

    Parameters
    ----------
    brickdict : :class:`dict`
        Look-up dictionary for a set of bricks, as made by, e.g.
        :func:`~desitarget.skyfibers.get_brick_info`.
    bricknames : :class:`~numpy.array`
        The names of the bricks in `brickdict` to process.
    drdir : :class:`str`, optional, defaults to None
        See :func:`~desitarget.randoms.get_quantities_in_a_brick`.
    zeros : :class:`bool`, optional, defaults to ``False``
        See :func:`~desitarget.randoms.get_quantities_in_a_brick`.
    cnts : :class:`bool`, optional, defaults to ``True``
        See :func:`~desitarget.skyfibers.get_brick_info`.

    Returns
    -------
    :class:`~numpy.ndarray`
        a numpy structured array with the same columns as returned by
        :func:`~desitarget.randoms.get_quantities_in_a_brick`.

    Notes
    -----
    - See :func:`~desitarget.randoms.select_randoms` for definitions of
      `nproc`, `density`, `dustdir`, `aprad`.

    """
    import legacyhalos.sharedmem
    
    drdir = os.getenv('LEGACY_SURVEY_DIR')

    nbricks = len(bricknames)
    print('Processing {} bricks from {}...t = {:.1f}s'.format(nbricks, drdir, time()-start))

    # ADM the critical function to run on every brick.
    def _get_quantities(brickname):
        """wrapper on get_quantities_in_a_brick() given a brick name"""
        these = brickname == cat_bricknames
        # Retrieve the quantities of interest at the sources on this brick. 
        return get_quantities_in_a_brick(ra[these], dec[these], brickname,
                                         drdir=drdir, dustdir=dustdir)

    # ADM this is just to count bricks in _update_status.
    nbrick = np.zeros((), dtype='i8')
    t0 = time()
    # ADM write a total of 25 output messages during processing.
    interval = nbricks // 100 # 25

    def _update_status(result):
        ''' wrapper function for the critical reduction operation,
            that occurs on the main parallel process '''
        if nbrick % interval == 0 and nbrick > 0:
            elapsed = time() - t0
            rate = nbrick / elapsed
            print('{}/{} bricks; {:.1f} bricks/sec; {:.1f} total mins elapsed'
                  .format(nbrick, nbricks, rate, elapsed/60.))
            # ADM if we're going to exceed 4 hours, warn the user.
            if nbricks/rate > 4*3600.:
                msg = 'May take > 4 hours to run. Run with bundlebricks instead.'
                print(msg)
                raise IOError(msg)
        nbrick[...] += 1    # this is an in-place modification.
        return result

    # - Parallel process input files.
    if nproc > 1:
        #pool = multiprocessing.Pool(nproc)
        pool = legacyhalos.sharedmem.MapReduce(np=nproc)
        with pool:
            qinfo = pool.map(_get_quantities, bricknames, reduce=_update_status)
    else:
        qinfo = list()
        for brickname in bricknames:
            qinfo.append(_update_status(_get_quantities(brickname)))

    # ADM concatenate the randoms into a single long list and resolve
    # ADM whether they are officially in the north or the south.
    qinfo = np.concatenate(qinfo)

    return qinfo

def get_brick_info(drdirs, counts=False, allbricks=False):
    """Retrieve brick names and coordinates from Legacy Surveys directories.

    Parameters
    ----------
    drdirs : :class:`list` or `str`
        A list of strings, each of which corresponds to a directory pointing
        to a Data Release from the Legacy Surveys. Can be of length one.
        e.g. ['/global/project/projectdirs/cosmo/data/legacysurvey/dr7'].
        or '/global/project/projectdirs/cosmo/data/legacysurvey/dr7'
        Can be None if `allbricks` is passed.
    counts : :class:`bool`, optional, defaults to ``False``
        If ``True`` also return a count of the number of times each brick
        appears ([RAcen, DECcen, RAmin, RAmax, DECmin, DECmax, CNT]).
    allbricks : :class:`bool`, optional, defaults to ``False``
        If ``True`` ignore `drdirs` and simply return a dictionary of ALL
        of the bricks.

    Returns
    -------
    :class:`dict`
        UNIQUE bricks covered by the Data Release(s). Keys are brick names
        and values are a list of the brick center and the brick corners
        ([RAcen, DECcen, RAmin, RAmax, DECmin, DECmax]).

    Notes
    -----
        - Tries a few different ways in case the survey bricks files have
          not yet been created.
    """
    # ADM convert a single input string to a list.
    if isinstance(drdirs, str):
        drdirs = [drdirs, ]

    # ADM initialize the bricks class, retrieve the brick information look-up
    # ADM table and turn it into a fast look-up dictionary.
    from legacyhalos.desiutil import Bricks
    bricktable = Bricks(bricksize=0.25).to_table()
    brickdict = {}
    for b in bricktable:
        brickdict[b["BRICKNAME"]] = [b["RA"], b["DEC"],
                                     b["RA1"], b["RA2"],
                                     b["DEC1"], b["DEC2"]]

    # ADM if requested, return the dictionary of ALL bricks.
    if allbricks:
        return brickdict

    bricknames = []
    for dd in drdirs:
        # ADM in the simplest case, read in the survey bricks file, which lists
        # ADM the bricks of interest for this DR.
        sbfile = glob(dd+'/*bricks-dr*')
        if len(sbfile) > 0:
            brickinfo = fitsio.read(sbfile[0])
            # ADM fitsio reads things in as bytes, so convert to unicode.
            bricknames.append(brickinfo['brickname'].astype('U'))
        else:
            # ADM hack for test bricks where we didn't generate the bricks file.
            fns = glob(os.path.join(dd, 'tractor', '*', '*fits'))
            bricknames.append([brickname_from_filename(fn) for fn in fns])

    # ADM don't count bricks twice, but record number of duplicate bricks.
    bricknames, cnts = np.unique(np.concatenate(bricknames), return_counts=True)

    # ADM only return the subset of the dictionary with bricks in the DR.
    if counts:
        return {bn: brickdict[bn] + [cnt] for bn, cnt in zip(bricknames, cnts)}
    return {bn: brickdict[bn] for bn in bricknames}

def imaging_properties(ra, dec, nproc=32, resolve=True, dustdir=None):
    """NOBS, DEPTHs (per-band), MASKs for input points in a Legacy Surveys DR.

    Parameters
    ----------
    drdir : :class:`str`
       The root directory pointing to a Data Release from the Legacy Surveys
       e.g. /global/project/projectdirs/cosmo/data/legacysurvey/dr7.
    density : :class:`int`, optional, defaults to 100,000
        The number of random points to return per sq. deg. As a typical brick is
        ~0.25 x 0.25 sq. deg. about (0.0625*density) points will be returned.
    nproc : :class:`int`, optional, defaults to 32
        The number of processes over which to parallelize.
    nside : :class:`int`, optional, defaults to nside=4 (214.86 sq. deg.)
        The (NESTED) HEALPixel nside to be used with the `pixlist` and `bundlebricks` input.
    pixlist : :class:`list` or `int`, optional, defaults to None
        Bricks will only be processed if the CENTER of the brick lies within the bounds of
        pixels that are in this list of integers, at the supplied HEALPixel `nside`.
        Uses the HEALPix NESTED scheme. Useful for parallelizing. If pixlist is None
        then all bricks in the passed `survey` will be processed.
    bundlebricks : :class:`int`, defaults to None
        If not None, then instead of selecting the skies, print, to screen, the slurm
        script that will approximately balance the brick distribution at `bundlebricks`
        bricks per node. So, for instance, if bundlebricks is 14000 (which as of
        the latest git push works well to fit on the interactive nodes on Cori and run
        in about an hour), then commands would be returned with the correct pixlist values
        to pass to the code to pack at about 14000 bricks per node across all of the bricks
        in `survey`.
    brickspersec : :class:`float`, optional, defaults to 2.5
        The rough number of bricks processed per second by the code (parallelized across
        a chosen number of nodes). Used in conjunction with `bundlebricks` for the code
        to estimate time to completion when parallelizing across pixels.
    dustdir : :class:`str`, optional, defaults to $DUST_DIR+'maps'
        The root directory pointing to SFD dust maps. If None the code
        will try to use $DUST_DIR+'maps') before failing.
    resolverands : :class:`boolean`, optional, defaults to ``True``
        If ``True``, resolve randoms into northern randoms in northern regions
        and southern randoms in southern regions.
    aprad : :class:`float`, optional, defaults to 0.75
        Radii in arcsec of aperture for which to derive sky fluxes
        defaults to the DESI fiber radius.

    Returns
    -------
    :class:`~numpy.ndarray`
        a numpy structured array with the same columns as returned by
        :func:`~desitarget.randoms.get_quantities_in_a_brick`.

    """
    if dustdir is None:
        dustdir = os.path.join(os.getenv('DUST_DIR'), 'maps')

    # Convert the input RA, Dec to healpixel numbers
    #from legacyhalos.misc import radec2pix
    #pixlist = np.unique(radec2pix(nside, ra, dec))
    with multiprocessing.Pool(nproc) as P:
        cat_bricknames = P.map(_get_brickname_from_radec, [(_ra, _dec, 0.25) for _ra, _dec in zip(ra, dec)])
    cat_bricknames = np.array(cat_bricknames)
    
    # ADM grab brick information for this data release. Depending on whether this
    # ADM is pre-or-post-DR8 we need to find the correct directory or directories.
    drdir = os.getenv('LEGACY_SURVEY_DIR')
    wcoadd = glob(os.path.join(drdir, '*', "coadd"))
    drdirs = [os.path.dirname(dd) for dd in wcoadd]

    print('Gathering information on all bricks.')
    brickdict = get_brick_info(drdirs, counts=True)
    # ADM this is just the UNIQUE brick names across all surveys.
    bricknames = np.array(list(brickdict.keys()))

    # Restrict to just the bricks of interest.
    bricknames = np.intersect1d(cat_bricknames, bricknames)

    # Recover the pixel-level quantities in the DR bricks.
    qinfo = imaging_properties_bricks(ra, dec, brickdict, bricknames, cat_bricknames,
                                      nproc=nproc, dustdir=dustdir)
    
    # ADM remove bricks that overlap between two surveys, if requested.
    if resolve:
        qinfo = doresolve(qinfo)

    return qinfo

def main():

    from argparse import ArgumentParser
    ap = ArgumentParser(description='Assemble imaging properties at the position of an input target sample.')
    ap.add_argument("--outfile", type=str, default='./redmapper-legacysurvey.fits', 
                    help='Output file name to write final catalog (.fits).')
    ap.add_argument("--nproc", type=int, help='Number of concurrent processes to use.')
    ap.add_argument("--nchunk", type=int, default=5, help='Number of chunks to process.')
    ap.add_argument("--chunk", type=int, default=0, help='Chunk number to process [0,...,nchunk-1].')
    ap.add_argument("--merge-chunks", action='store_true', help="Merge the individual chunks")
    ap.add_argument("--noresolve", action='store_true', help="Do NOT resolve into north/south.")
    ap.add_argument("--satellites", action='store_true', help="Process the satellites (default is to do the centrals).")

    ns = ap.parse_args()

    rmversion = 'v6.3.1'
    if ns.satellites:
        suffix = 'satellites'
    else:
        suffix = 'centrals'

    # Chunk the sample so it'll finish in finite time.
    if ns.merge_chunks:
        from astropy.table import vstack
        outfile = os.path.join(os.getenv('REDMAPPER_DIR'), rmversion,
                               'legacysurvey-dr8-{}-{}-lgt5.fits'.format(suffix, rmversion))
        out = []
        for ii in np.arange(ns.nchunk):
            chunkfile = os.path.join(os.getenv('REDMAPPER_DIR'), rmversion,
                                     'legacysurvey-dr8-chunk{}-{}-{}-lgt5.fits'.format(ii, suffix, rmversion))
            cat = Table(fitsio.read(chunkfile))
            if ii == 0:
                hdr = fitsio.read_header(chunkfile)
            print('Read {} galaxies from {}'.format(len(cat), chunkfile))
            out.append(cat)
        out = vstack(out)
        print('Writing {} galaxies to {}'.format(len(out), outfile))
        out.write(outfile, header=hdr, overwrite=True)

    ngal = legacyhalos.io.read_redmapper(satellites=ns.satellites, get_ngal=True)
    index = np.array_split(np.arange(ngal), ns.nchunk)

    cat = legacyhalos.io.read_redmapper(satellites=ns.satellites, index=index[ns.chunk])

    #from astrometry.libkd.spherematch import trees_match, tree_build_radec, match_radec
    #randomfile = os.path.join(surveydir, 'randoms', 'randoms-inside-dr8-0.31.0-1.fits')
    #rnd = fitsio.read(randomfile)
    #print('Read {} randoms from {}'.format(len(rnd), randomfile))
    #kdrnd = tree_build_radec(rnd['RA'], rnd['DEC'])
    #m1, m2, d12 = trees_match(kdrnd, kdcat, radius)
    #m1, m2, d12 = match_radec(rnd['RA'], rnd['DEC'], cat['RA'], cat['DEC'], 3/3600.0, nearest=True)

    # Go looking for a maskbits file to steal the header for the bit names.
    hdr = None

    surveydir = os.getenv('LEGACY_SURVEY_DIR')
    if not os.path.exists(surveydir):
        print('Survey directory does not exist: {}'.format(surveydir))
        sys.exit(1)

    gen = iglob(os.path.join(surveydir, "*", "coadd", "*", "*", "*maskbits*"))
    try:
        fn = next(gen)
        hdrall = fitsio.read_header(fn, 1)
    except StopIteration:
        gen = iglob(os.path.join(surveydir, "coadd", "*", "*", "*maskbits*"))
        fn = next(gen)
        hdrall = fitsio.read_header(fn, 0)
        
    # ADM retrieve the record dictionary for the entire header.
    rmhdr = vars(hdrall)
    # ADM write only the maskbits-relevant headers to a new header.
    hdr = fitsio.FITSHDR()
    for record in rmhdr['_record_map']:
        if 'BITNM' in record:
            hdr[record] = rmhdr['_record_map'][record]

    res = imaging_properties(cat['RA_SDSS'], cat['DEC_SDSS'], nproc=ns.nproc,
                             resolve=not (ns.noresolve))

    # Write out.
    outfile = os.path.join(os.getenv('REDMAPPER_DIR'), rmversion,
                           'legacysurvey-dr8-chunk{}-{}-{}-lgt5.fits'.format(ns.chunk, suffix, rmversion))
    
    print('Writing {} galaxies to {}'.format(len(res), outfile))
    fitsio.write(outfile, res, header=hdr, clobber=True)

if __name__ == '__main__':
    main()

#!/usr/bin/env python

"""
MPI wrapper for legacyhalos_coadds.
"""

from __future__ import absolute_import, division, print_function

import os, sys, glob, time, subprocess
import argparse

import numpy as np

def init_survey():
    """Instantiate the LegacySurveyData object."""
    from legacypipe.survey import LegacySurveyData

    dr5_dir = os.path.join(os.sep, 'project', 'projectdirs', 'cosmo', 'data', 'legacysurvey', 'dr5')
    return LegacySurveyData(cache_dir=dr5_dir)

def _missing(sample, comm=None, filetype='coadds'):
    """Find missing data of a given filetype."""
    
    from legacyhalos.io import get_objid

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    if filetype == 'coadds':
        filesuffix = '-resid.jpg'
    else:
        print('Unrecognized file type!')
        raise ValueError

    objid, objdir = get_objid(sample)

    ngal = len(sample)
    indices = np.arange(ngal)
    todo = np.ones(ngal, dtype=bool)
    
    for ii, (objid1, objdir1) in enumerate( zip(objid, objdir) ):
        residfile = os.path.join(objdir1, '{}-{}'.format(objid1, filesuffix))
        if os.path.exists(residfile):
            todo[ii] = False

    indices[todo]

    if len(indices) == 0:
        if rank == 0:
            print('All galaxies of filetype {} have been processed!'.format(filetype))
        return list()

    groups = np.array_split(indices, size)

    return groups

def missing_coadds(sample, comm=None):
    '''Find the galaxies that do not yet have coadds

    '''
    return _missing(sample, comm=None, filetype='coadds')

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--ncpu', type=int, help='number of multiprocessing processes per MPI rank.')
    parser.add_argument('--mpi', action='store_true', help='Use MPI parallelism')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose output.')

    args = parser.parse_args()

    if args.mpi:
        from mpi4py import MPI
        comm = MPI.COMM_WORLD
        rank = comm.Get_rank()
    else:
        comm = None
        rank = 0

    if os.getenv('NERSC_HOST') == 'cori':
        maxproc = 64
    elif os.getenv('NERSC_HOST') == 'edison':
        maxproc = 48
    else:
        maxproc = 4

    if args.ncpu is None:
        args.ncpu = maxproc // 2

    # Read the sample to see how many more galaxies we need to process.
    if rank == 0:

        import legacyhalos.io
        from astrometry.util.fits import merge_tables

        outdir = legacyhalos.io.analysis_dir()
        sample = legacyhalos.io.read_catalog(extname='LSPHOT', upenn=True,
                                             columns=('ra', 'dec', 'bx', 'by', 'brickname', 'objid'))
        rm = legacyhalos.io.read_catalog(extname='REDMAPPER', upenn=True,
                                         columns=('mem_match_id', 'z', 'r_lambda'))
        sample.add_columns_from(rm)
        #sample.new_columns = T1.c1 + T.c4

        print('Hack -- 10 galaxies!')
        sample = sample[1050:1060]
        print('Read {} galaxies.'.format(len(sample)))

        legacyhalos_coadds(sample, args, comm=comm, outdir=outdir)

def plan(args, sample, comm=None, outdir=None):
    """Make a plan."""

    t0 = time.time()
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    if rank == 0:
        indices = sample_left_todo(sample, outdir=outdir)
    else:
        indices = None

    if comm is not None:
        indices = comm.bcast(indices, root=0)

    if len(indices) == 0:
        if rank == 0:
            print('All galaxies have been processed!')
        return list(), list(), list()

    # Divide the remaining sample among the ranks.    
    groups, grouptimes = group_sample_todo(indices, comm=comm)

    plantime = time.time() - t0
    if plantime + np.max(grouptimes) <= (25*60):
        queue = 'debug'
    else:
        queue = 'regular'

    numnodes = len(groups)

    if os.getenv('NERSC_HOST') == 'cori':
        maxproc = 64
    elif os.getenv('NERSC_HOST') == 'edison':
        maxproc = 48
    else:
        maxproc = 4

    if args.ncpu is None:
        args.ncpu = maxproc // 2

    ##- scale longer if purposefullying using fewer cores (e.g. for memory)
    #if args.ncpu < maxproc // 2:
    #    scale = (maxproc // 2) / args.ncpu
    #    grouptimes *= scale
    #
    jobtime = int(1.15 * (plantime + np.max(grouptimes)))
    jobhours = jobtime // 3600
    jobminutes = (jobtime - jobhours*3600) // 60
    jobseconds = jobtime - jobhours*3600 - jobminutes*60

    if rank == 0:
        print('#!/bin/bash')
        print('#SBATCH -N {}'.format(numnodes))
        print('#SBATCH -p {}'.format(queue))
        print('#SBATCH -J legacyhalos-coadds')
        if os.getenv('NERSC_HOST') == 'cori':
            print('#SBATCH -C haswell')
        print('#SBATCH -t {:02d}:{:02d}:{:02d}'.format(jobhours, jobminutes, jobseconds))
        print()
        print('# {} galaxies'.format(len(indices)))
        ### print('# plan time {:.1f} minutes'.format(plantime / 60))
        print('# Using {} nodes in {} queue'.format(numnodes, queue))
        print('# expected rank runtimes ({:.1f}, {:.1f}, {:.1f}) min/mid/max minutes'.format(
            np.min(grouptimes)/60, np.median(grouptimes)/60, np.max(grouptimes)/60
        ))
        print()
        print('nodes=$SLURM_JOB_NUM_NODES')
        print('srun -N $nodes -n $nodes -c {} {} --mpi --ncpu {}'.format(
            maxproc, os.path.abspath(__file__), args.ncpu,
        ))

    return indices, groups, grouptimes

def legacyhalos_coadds(sample, args, comm=None, outdir=None):
    """Generate the coadds.

    """
    from legacyhalos.io import get_objid
    from legacyhalos.coadds import legacyhalos_coadds

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    # Determine how many more coadds we need to make and chunk them.
    t0 = time.time()
    if rank == 0:
        print('Starting at {}'.format(time.asctime()))

    groups = missing_coadds(sample, comm=comm)
    if len(groups) == 0:
        return

    #sys.stdout.flush()
    #if comm is not None:
    #    indices = comm.bcast(indices, root=0)

    # Initialize and then broadcast the LegacySurveyData() object to all ranks.
    if rank == 0:
        survey = init_survey()
        
    if comm is not None:
        survey = comm.bcast(survey, root=0)
        groups = comm.bcast(groups, root=0)
        sample = comm.bcast(sample, root=0)

    # Loop on the remaining objects.
    #for (ii, objid, objdir) in groups[rank]:
    for ii in groups[rank]:

        objid, objdir = get_objid(sample[ii])

        logfile = os.path.join(objdir, '{}-coadds.log'.format(objid))
        print('LOGGING to {}'.format(logfile))

        print('---- rank {} objid {} {}'.format(rank, objid, time.asctime()))
        sys.stdout.flush()

        import pdb ; pdb.set_trace()

        try:
            t0 = time.time()
            with open(logfile, 'a') as log:
                #sys.stdout = log
                #sys.stderr = log
                err = legacyhalos_coadds(survey, sample[ii], radius, outdir,
                                         ncpu=args.ncpu, verbose=args.verbose)
            
            runtime = (time.time()-t0) / 60
            print('SUCCESS: objid {} coadds on rank {} took {:.1f} minutes'.format(strid, rank, runtime))

        except:
            print('FAILED: objid {} coadds on rank {} raised an exception'.format(strid, rank))
            import traceback
            traceback.print_exc()

    print('---- rank {} is done'.format(rank))
    sys.stdout.flush()

    if comm is not None:
        comm.barrier()

    #if rank == 0:
    #    for outfile in zbfiles:
    #        if not os.path.exists(outfile):
    #            print('ERROR missing {}'.format(outfile))

        print('All done at {}'.format(time.asctime()))

if __name__ == '__main__':
    main()
